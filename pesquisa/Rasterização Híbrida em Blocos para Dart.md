Renderização 2D Otimizada em CPU: Técnicas Existentes e Novo Algoritmo em Dart
1. Técnicas e Algoritmos Existentes Relevantes

Rasterização por varredura (scanline): Técnica clássica para renderizar gráficos vetoriais preenchidos. Percorre-se a imagem linha por linha (scanlines) mantendo uma tabela de arestas ativas (AET) para determinar segmentos a preencher em cada linha. É usada em bibliotecas como Skia e FreeType, que implementam variações desse algoritmo de forma otimizada. Suporta curvas Bézier (após subdivisão em pequenos segmentos lineares) e garante preenchimento conforme regras de preenchimento (par/impar ou não-zero). A rasterização por scanline pode incluir cálculo de área de cobertura fracionária por pixel para anti-aliasing de alta qualidade, evitando serrilhados visíveis.

Buffer de acumulação de áreas (diferenças): Abordagem na qual as contribuições das bordas do vetor são acumuladas em um buffer auxiliar (por exemplo, um array de floats) e depois integradas em um único passo sobre a imagem final. Essa técnica, utilizada em renderizadores de fontes modernos como stb_truetype e font-rs, marca incrementos de área “entrando” ou “saindo” em cada pixel atravessado pela aresta, e depois realiza uma soma cumulativa para obter a cobertura final de cada pixel. O loop de preenchimento resultante é simples e sem bifurcações, executando a mesma operação em todos os pixels (dentro ou fora da forma) e aproveitando bem pipelines modernos de CPU. Isso traz grande eficiência em formas pequenas (ex: glyphs de texto) ao custo de tocar alguns pixels fora da forma – um compromisso vantajoso para pequenas resoluções. Estudos mostraram ganhos significativos: um protótipo em Rust atingiu até ~7,6× a velocidade do FreeType em tamanhos grandes de fonte (e ~4× em tamanhos pequenos) usando essa técnica de acumulação otimizada.

Algoritmos de linha (Bresenham e Xiaolin Wu): Para renderizar segmentos de reta rápidos, o algoritmo de Bresenham usa aritmética inteira e incrementos discretos para decidir quais pixels acender, sem multiplicações ou divisões, sendo extremamente eficiente em CPU. No entanto, ele produz linhas “denteadas” (aliasing). Já o algoritmo de Xiaolin Wu realiza uma forma de anti-aliasing, calculando intensidades parciais para os dois pixels vizinhos à linha em cada passo, suavizando a linha resultante. Esses algoritmos ilustram o compromisso entre velocidade e qualidade: Bresenham é padrão pela velocidade, enquanto Wu (e algoritmos similares, como Gupta-Sproull) produz qualidade superior distribuindo a intensidade entre pixels adjacentes. Em curvas (como arcos ou Béziers), técnicas similares podem ser aplicadas subdividindo a curva em pequenos trechos lineares e aplicando algoritmos de linha ou preenchimento apropriados em cada trecho.

Supersampling e filtragem: Consiste em renderizar a cena em resolução maior e depois reduzir (downsample) com um filtro, suavizando as bordas. Por exemplo, desenhar 2× ou 4× maior e então aplicar média para obter o resultado final antialiased. Garante alta qualidade de antialiasing sem cálculos analíticos complexos, mas aumenta muito o custo de processamento (por exemplo, 4× supersampling implica 16× mais pixels). Há variações adaptativas que apenas supersampleiam regiões próximas às bordas dos vetores para mitigar o custo. Embora simples de implementar, o supersampling puro não é o mais eficiente em CPU, sendo geralmente substituído por métodos analíticos de cobertura de pixel (como os mencionados scanline ou Wu) que computam diretamente valores de cinza de cada pixel.

Signed Distance Fields (SDF): Técnica na qual as formas vetoriais (especialmente texto) são pré-processadas em uma textura que armazena, para cada ponto, a distância até a borda mais próxima. Em tempo de renderização, em vez de rasterizar geometricamente o vetor, faz-se um simples teste do valor do campo de distância em cada pixel para determinar se está dentro ou fora e o quão próximo da borda (permitindo calcular um nível de cinza de antialiasing). SDFs permitem escalabilidade: um único SDF de um glifo pode gerar texto de vários tamanhos sem recalcular a rasterização, com boa qualidade visual em tamanhos medianos. No entanto, podem apresentar perda de detalhe em bordas muito finas ou tamanhos pequenos se a resolução do campo for limitada. Ainda assim, é uma técnica popular em engines de jogos para texto rápido, pois o custo de amostrar a textura (e eventualmente aplicar um threshold) é baixo e independe da complexidade do contorno original. Há variações como MSDF (Multichannel SDF) que usam múltiplos canais de distância para preservar cantos afiados e detalhes, melhorando a qualidade visual. Embora normalmente gerados off-line ou via GPU, SDFs podem ser usados em CPU se os campos forem pré-computados ou computados uma vez para cada forma e reutilizados.

Tesselação em triângulos: Transforma curvas e formas complexas em um conjunto de pequenos triângulos (ou outros polígonos simples, como trapezóides) e então rasteriza esses triângulos. Essa abordagem é alinhada ao pipeline tradicional de GPUs 3D (que possuem hardware dedicado para rasterizar triângulos rapidamente). Em CPU, pode-se fazer algo similar: usar algoritmos de rasterização de triângulos (por exemplo, interpolação barycêntrica ou scanline por triângulo) que são bem compreendidos e podem ser vetorizados. A tesselação (triangulação) de um path Bézier é O(n) no número de segmentos gerados e adiciona overhead, mas depois a rasterização de cada triângulo é simples. Bibliotecas como a Rust Lyon seguem esse caminho ao preparar malhas de triângulos a partir de paths 2D. A vantagem é poder usar otimizações de renderização 3D (e até z-buffer para composição ordenada) também no contexto 2D. Porém, em CPU pura, rasterizar centenas ou milhares de triângulos de uma forma pode ser menos eficiente do que um algoritmo especializado que processa a forma como um todo (pois triângulos individuais introduzem redundâncias e overhead de loop). Assim, essa técnica costuma ser mais útil se eventualmente for aproveitar aceleração por GPU ou paralelismo SIMD de forma eficaz.

Rasterização de cena inteira (one-pass): Em vez de rasterizar cada forma vetorial separadamente (pintando do fundo para frente, com sobreposição), esta técnica tenta processar todas as formas de uma só vez, varrendo a tela apenas uma vez. Por exemplo, um “rasterizador de cena completa” utiliza uma única varredura (scanline) que considera entradas e saídas de todas as formas simultaneamente. Assim, cada pixel é calculado apenas uma vez com o resultado final já composto, evitando o problema de overdraw (quando o mesmo pixel é escrito múltiplas vezes por formas sobrepostas). Rumores indicam que o runtime do Adobe Flash usava abordagem de varredura única, e há implementações open-source experimentais como a de Jeff Muizelaar. Embora difícil de implementar de forma geral (especialmente com transparências e misturas de cores), essa técnica ataca diretamente o custo de memória e cache causado por múltiplos desenhos sobre o mesmo pixel. Reduzir overdraw é crucial, pois na rasterização 2D em CPU o gargalo muitas vezes é a banda de memória ao escrever muitos pixels repetidamente, não apenas o cálculo geométrico.

Paralelismo por subdivisão: Aproveitar múltiplos núcleos de CPU dividindo a imagem ou as formas em partes a serem rasterizadas em paralelo. Pode-se dividir a tela em blocos ou faixas e renderizar cada parte em um thread separado, ou distribuir formas diferentes entre threads (desde que possam ser compostas depois). Bibliotecas modernas de renderização em CPU, como Blend2D, foram projetadas com multithreading em mente (por exemplo, dividindo o framebuffer em bandas). Em hardware atual, um núcleo consegue rasterizar em tempo real frames Full HD; usando 4 threads, poderíamos atingir 4K sem problemas em cenários de UI típicos. O desafio na Dart puro é que as threads são representadas por isolates (isolados) que não compartilham memória, então dividir o trabalho requer copiar ou segmentar os dados de pixel entre isolados, o que tem custo. Ainda assim, a possibilidade de paralelismo existe: por exemplo, quatro isolates processando quadrantes diferentes de uma imagem poderiam acelerar um rasterizador, contanto que haja como reunir o resultado eficientemente no final. O uso de paralelismo reduz o tempo total linear de processamento (idealmente quase dividindo pelo número de núcleos), mas não altera a complexidade O(N) em relação ao número total de pixels – é uma melhoria constante, útil sobretudo para imagens grandes ou cenas complexas.

Renderização de fontes TrueType: As fontes TrueType são definidas por curvas Bézier quadráticas e instruções de hinting. As técnicas acima (scanline, acumulação, etc.) aplicam-se à rasterização dos glifos vetoriais. O FreeType, por exemplo, usa scanline com alta qualidade e suporta hinting – pequenos ajustes nos contornos para alinhá-los à grade de pixels e melhorar a legibilidade em tamanhos pequenos. Isso não acelera a renderização, mas evita perda de qualidade visual. Outra técnica específica de texto é a renderização subpixel (ClearType), que trata cada subpixel de cor (RGB) separadamente para aumentar a resolução horizontal efetiva do texto em monitores LCD. Isso produz texto mais nítido aproveitando a estrutura física da tela, ao custo de cálculos de três componentes por pixel e possíveis artefatos de cor. Em contexto de geração de PNG/PDF, o subpixel pode ser opcional – para imagens destina-se normalmente a monitores, enquanto PDFs muitas vezes preferem texto vetorial puro. Vale notar que renderizadores como o citado font-rs exploram desempenho em CPU omitindo estruturas complexas: evitam alocações dinâmicas durante o parsing e rasterização, usando iteradores e cálculos densos em memória contígua para extrair o máximo do hardware moderno.

2. Comparação de Desempenho e Aplicabilidade das Técnicas

Cada algoritmo acima apresenta vantagens em determinados cenários, equilibrando desempenho e qualidade:

Scanline vs. Acumulação: O algoritmo de scanline tradicional é eficiente para formas grandes porque evita tocar pixels totalmente fora do contorno – ele trabalha de forma sparse, calculando apenas onde necessário. Entretanto, envolve lógica condicional para inserir/remover arestas e calcular interseções por linha, o que introduz ramificações de controle. Já o método de buffer de acumulação (diferenças) torna o loop principal muito simples e sequencial (sem muitas condicionais), explorando o throughput da CPU moderna. Ele brilha em formas pequenas (ex: texto de tamanho pequeno a médio), onde o custo de percorrer alguns pixels “vazios” a mais é irrisório comparado ao ganho de eficiência interna. No entanto, à medida que a resolução da forma cresce (ex: fontes muito grandes ou formas preenchendo a tela), o custo quadrático de percorrer um grande buffer denso passa a superar a vantagem, tornando o scanline mais atrativo para grandes áreas. Isso sugere que não há “tamanho único” ideal – implementações de alto desempenho muitas vezes combinam estratégias: um rasterizador pode usar acumulação para pequenos glifos e scanline para formas amplas.

Qualidade vs. Velocidade em Linhas: O algoritmo de Bresenham é extremamente rápido e simples, portanto adequado para desenhar muitos elementos lineares pequenos (como wireframes, gridlines) onde um leve serrilhado não seja crítico. Ele evita operações de ponto flutuante e calcula cada próximo pixel com poucas somas, favorecendo CPUs sem hardware de ponto flutuante (ou situações de performance crítica). Em contrapartida, Xiaolin Wu e outros métodos anti-aliased consomem um pouco mais de processamento por pixel (calculando fatores de intensidade). Em termos de complexidade, ainda são O(N) no comprimento da linha, mas com um multiplicador constante maior devido aos cálculos de intensidade (geralmente envolvendo operações de ponto flutuante ou lookup de tabelas). Na prática, Bresenham permanece popular por sua agilidade, enquanto Wu é empregado quando a suavização é necessária para qualidade profissional. Em renders modernos, a penalidade do Wu é muito pequena frente ao benefício visual, então costuma-se preferir linhas anti-aliased a menos que o dispositivo alvo seja extremamente limitado.

Supersampling vs. Métodos Analíticos: Supersampling é conceitualmente simples e oferece qualidade alta dependendo do fator de amostragem. Porém, seu custo cresce quadraticamente com o fator de escala (e linearmente com o número de objetos, pois cada objeto é desenhado em maior resolução). Métodos analíticos (como calcular exatamente a área de cobertura de cada pixel por uma forma) atingem qualidade comparável com menos trabalho extra. Por exemplo, o rasterizador do stb_truetype originalmente usava 5× supersampling e depois reduzia, mas a versão 2 trocou para o algoritmo de diferenças justamente por ser mais rápida e igualmente suave. Supersampling ainda pode ser útil em contextos onde algoritmos analíticos seriam muito complexos de implementar (por exemplo, para efeitos especiais ou quando se pode aproveitar múltiplos núcleos/GPUs para diluir o custo). Em geral, contudo, algoritmos dedicados que calculam frações de área (via interseção de trapezóides, etc.) entregam qualidade sem “brute force”, sendo preferíveis em renderização 2D de rotinas frequentes como desenho de texto e formas básicas.

SDF vs. Rasterização Direta: O uso de Signed Distance Fields representa um trade-off diferente – ele desloca o custo para uma etapa de pré-processamento. Se você tiver formas fixas que serão redimensionadas ou renderizadas repetidamente (ex: fontes em um jogo), gerar uma textura SDF para cada caractere é custoso apenas uma vez, depois a renderização de texto é extremamente rápida (meros acessos a memória e comparações para cada pixel) e escalável a resoluções diferentes. Além disso, SDF naturalmente proporciona bordas suaves ao thresholdar o campo de distância para produzir a forma. Por outro lado, se as formas são dinâmicas (geradas em tempo real ou únicas), criar um SDF pode não compensar – essencialmente você rasteriza a forma em alta resolução para construir o campo, e aí rasteriza de novo ao amostrar o SDF. Nesses casos, é melhor rasterizar diretamente numa única passagem analítica. Em termos de qualidade, SDFs podem perder detalhes finos se não calibrados, mas técnicas como MSDF mitigam isso. Em suma, SDF é ótimo para cenários de muito reuso e necessidade de escalabilidade (ex.: muitas instâncias do mesmo ícone ou fonte), enquanto rasterização direta customizada tende a ganhar em qualidade máxima para conteúdo renderizado pontualmente.

Tesselação e Triangulação: Converter vetores em triângulos e rasterizá-los pode aproveitar décadas de otimizações de pipelines 3D. Em GPU isso é claramente benéfico – já em CPU, o balanço não é tão óbvio. Rasterizadores de triângulo em CPU podem ser super otimizados com SIMD, mas a sobrecarga de ter muitas pequenas primitivas pode pesar. Skia e outras bibliotecas às vezes adotam tesselação para certas operações (por exemplo, aplicam um rasterizador de trapezóides internamente). A abordagem de triangulação brilha quando pode ser feita uma vez e reutilizada: por exemplo, se você vai animar uma forma vetorial, manter a malha triangulada e apenas transformá-la evita recalcular interseções ou subdivisões a cada frame. Em um contexto estático (como gerar um PDF ou imagem uma vez), tesselar e rasterizar de imediato pode ser comparável em custo a rasterizar diretamente por scanline. A decisão depende também da complexidade geométrica: para formas muito complexas, quebrar em triângulos menores torna mais previsível o tempo de rasterização, enquanto algoritmos como scanline têm complexidade dependente do número de interseções por linha (que pode variar conforme geometria). Em resumo, a tesselação fornece um caminho unificado (tudo vira triângulo), útil para hardware gráfico e potencialmente para paralelismo, mas pode introduzir overhead desnecessário em software puro se algoritmos especializados lidam com a forma de maneira mais direta.

Rasterização One-pass vs. Múltiplas Passes (overdraw): O método tradicional de composição é desenhar formas de trás para frente, escrevendo pixels várias vezes em áreas onde formas se sobrepõem. Isso é simples e geral, mas como vimos, pode desperdiçar trabalho – por exemplo, na famosa imagem do tigre do Ghostscript, muitos pixels são pintados dezenas de vezes devido às camadas de formas. Esse sobretrabalho satura a memória, diminuindo caches e prejudicando o desempenho global. A rasterização de cena inteira resolve isso tocando cada pixel apenas uma vez com a cor final. Na prática, poucas implementações 2D usam full-scene rendering por causa da complexidade (especialmente para suportar transparências, blend modes, etc.). Assim, alguns comprometem: por exemplo, motores gráficos 3D simulam isso usando um z-buffer e desenhando objetos opacos em ordem frontal (front-to-back) para evitar sobrescrever pixels já finalizados. Em CPU pura 2D, poderia-se imaginar usar algo similar – um buffer de profundidade trivial (nível de camada) para evitar desenhar pixels que já estão cobertos por algo acima. Contudo, gerenciar isso em nível de pixels também tem custo. Em suma, evitar overdraw é desejável para performance (menos escrita de memória), mas as soluções variam de difíceis (varredura global) a moderadas (ordenação e recorte de formas). Em cenários controlados (como UI com formas opacas simples), técnicas de ordenação podem acelerar bastante a composição, mas em geral o método robusto continua sendo back-to-front, aceitando o custo extra por simplicidade de implementação.

Impacto do Multithreading: Adicionar threads paralelas não altera a eficiência intrínseca de um algoritmo (um algoritmo O(N) continua O(N) mesmo com 4 threads, apenas o N é dividido entre eles). Porém, na prática, isso pode significar aproveitar 4× mais operações por segundo em um chip quad-core, um ganho substancial para renderizar resoluções altas ou múltiplos documentos simultaneamente. Por exemplo, Blend2D planeja uma rasterização multithread eficiente e escalável por bandas. No contexto de UI interativa, nem sempre se pode usar todos os núcleos para desenho (pois o app compete com outras tarefas do sistema), mas em geração offscreen de imagens/PDF, normalmente podemos sim tirar proveito de núcleos ociosos. Portanto, técnicas algorítmicas devem considerar a possibilidade de paralelismo: algoritmos que dividem naturalmente o trabalho em partes independentes (por linhas, blocos ou objetos) são mais fáceis de paralelizar. Um exemplo positivo é dividir a imagem em regiões (por exemplo quadrantes) e rasterizar cada uma em paralelo, ou dividir um conjunto de 100 formas entre 4 threads (~25 formas por thread). Já um algoritmo que exige conhecimento global a cada passo (como a varredura de cena inteira) é mais difícil de distribuir entre threads. Assim, a aplicabilidade de cada técnica também depende de quão bem ela se adapta a execução concorrente – em geral, métodos baseados em subdivisão espacial e tesselação são amigáveis a paralelismo, enquanto métodos estritamente sequenciais (varredura única global) não o são.

Bibliotecas nativas comparadas: Bibliotecas escritas em C/C++ otimizadas para rasterização 2D (Skia, Cairo, AGG, etc.) apresentam desempenhos próximos entre si, com diferenças de implementação. O Skia, utilizado pelo Chrome/Flutter, tende a ser muito rápido e multi-plataforma, com opção de usar GPU ou CPU conforme o caso – no CPU costuma superar o Cairo em alguns cenários, embora ajustes e otimizações de plataforma influenciem. O Cairo foca em precisão e qualidade, mas carece de aceleração GPU moderna (o backend OpenGL foi descontinuado por não trazer ganhos). O AGG (Anti-Grain Geometry) é uma biblioteca somente CPU conhecida pela altíssima fidelidade (subpixel exato e anti-aliasing) e performance respeitável; em comparativos históricos era uma das mais rápidas renderizações 2D anti-aliased em CPU. Já projetos mais recentes como Blend2D empregam otimizações agressivas: geração dinâmica de código (JIT) para rotinas críticas, rasterização por spans altamente otimizada e uso extensivo de instruções SIMD, conseguindo superar bibliotecas tradicionais em vários testes. Por exemplo, o Blend2D otimiza todas as etapas – desde construir as arestas das geometrias até o preenchimento – e planeja cada chamada de desenho para reduzir sobrecargas, resultando em throughput maior de operações gráficas. Isso mostra que mesmo em CPU há espaço para inovações que rendem múltiplos de ganho, embora muitas dessas otimizações avancadas (JIT, SIMD manual, etc.) estejam fora do alcance de implementações puras em linguagens gerenciadas como Dart, a não ser via chamadas nativas. Em suma, o estado da arte em CPU 2D hoje combina engenharia cuidadosa (minimizar branches, maximizar memória contígua), paralelismo e uso de recursos de baixo nível do hardware para atingir tanto velocidade quanto qualidade.

3. Particularidades do Dart e Interoperabilidade com Bibliotecas Nativas

O ecossistema Dart, ao ser uma linguagem gerenciada com máquina virtual (ou runtime AOT), traz considerações especiais para implementações de renderização de baixo nível:

Desempenho de Dart vs. C/C++: Código Dart puro geralmente não atinge a mesma velocidade de código C/C++ altamente otimizado para tarefas de pixel. Loops pesados manipulando milhões de pixels/samples podem sofrer overhead de verificação de limites de array, coleta de lixo e ausência de otimizações como SIMD explícito. Como exemplo, a única biblioteca de processamento de imagem puramente Dart atualmente (package:image) é conhecida por ser muito lenta em operações básicas comparado a equivalentes nativos. Usuários reportam operações de escala de imagem levando dezenas de segundos em Dart puro, enquanto em C/C++ ou usando APIs nativas seriam instantâneas. Isso indica que, embora Dart seja “rápido o suficiente” para muitas aplicações de alto nível, para computação gráfica intensiva ainda há uma lacuna de performance.

Gerenciamento de memória e GC: Dart possui garbage collector, o que significa que alocações excessivas durante rasterização podem introduzir pausas ou overhead indesejado. Um rasterizador ideal em Dart deve:

Usar buffers prealocados (por exemplo, um Uint8List ou Uint32List para o framebuffer) em vez de criar novos objetos pixel a pixel.

Evitar criar objetos temporários para representações geométricas dentro de loops intensivos (em vez disso, trabalhar com tipos primitivos ou estruturar cálculos de forma enxuta). Por exemplo, ao iterar por arestas, usar índices e listas tipadas ao invés de instanciar muitas classes de ponto ou retângulo.

Cuidar com o uso de double para cálculos: embora o Dart seja eficiente com ponto flutuante (especialmente em modo JIT), em AOT certos cálculos podem não ser tão otimizados. Considerar aritmética fixed-point (ponto fixo em int) pode ser benéfico para evitar conversões e ajudar a previsibilidade, mas torna o código mais complexo. Em geral, garantir que operações críticas usem tipos nativos do Dart (int 64-bit, double 64-bit) para maximizar o uso do JIT/AOT otimizado.

Isolates e Paralelismo: Diferentemente de threads nativas, isolates do Dart não compartilham memória, o que complica dividir o framebuffer diretamente entre threads. Contudo, a API recente de TransferableTypedData permite enviar buffers de bytes de um isolate a outro sem copiá-los (transferência de posse). Isso pode ser usado para implementar processamento paralelo: por exemplo, o isolate principal divide a imagem em 4 quadrantes, cria 4 isolates trabalhadores, enviando a cada um os dados relevantes (geometrias ou um buffer vazio para preencher). Cada trabalhador rasteriza sua porção e devolve o resultado. O custo de spin-up de isolates e transferência pode ser significativo para tarefas pequenas, então o paralelismo em Dart compensa mais em imagens grandes ou jobs batch (geração de muitos gráficos), em que o overhead inicial é amortizado. Em cenários de linha de comando ou servidor (não tempo real UI), esse modelo de “map-reduce” manual com isolates pode ser viável para acelerar a renderização usando todos os núcleos.

Interoperabilidade via FFI: O Dart oferece FFI (Foreign Function Interface) para chamar código nativo C/C++. Isso significa que, em tese, é possível integrar uma biblioteca como FreeType, Skia, Cairo etc., ou escrever rotinas críticas em C/C++ e chamá-las a partir do Dart. O FFI no Dart atualmente tem um certo overhead por chamada, similar a chamar uma função dinâmica do SO. Portanto, chamadas freqüentes de função nativa (ex: desenhar pixel a pixel via FFI) seriam péssimas. A estratégia adequada é fazer poucas chamadas englobando muito trabalho – por exemplo, chamar uma função nativa “rasterizePath” passando-lhe toda a descrição da forma e o buffer de destino, deixando o loop interno 100% em C. Isso minimiza o vai-e-vem entre Dart e nativo. De fato, muitas soluções de “alto desempenho em Dart” na comunidade se resumem a isso: usar C/C++ por trás dos panos. Como apontado por desenvolvedores, dizer que algo é “em Dart” pode ser enganoso se na verdade todo trabalho pesado ocorre em C via FFI. Para manter a pureza do Dart, evitar FFI seria ideal, mas deve-se reconhecer que atualmente, tarefas computacionalmente intensivas podem rodar várias vezes mais rápido fora do VM. Há casos práticos relatados de funções de processamento reimplementadas em C++ e chamadas por FFI rodando 3× mais rápido que a versão Dart otimizada equivalente.

Linguagem e recursos do Dart: Dart carece de algumas funcionalidades de baixo nível que facilitam otimizações, como tipos de largura fixa diretamente manipuláveis (além dos arrays tipados). Por exemplo, não há um tipo uint8 escalar – deve-se usar um Uint8List. O comentário na issue do SDK sugere que a falta de tipos numéricos mais ricos (como int8, intrinsics SIMD) pode explicar parte da lentidão do pacote image. A VM Dart JIT tem se tornado bem otimizada para código “normal”, mas o perfil de um rasterizador (loops intensivos de cálculo numérico) pode não receber tantas otimizações quanto, digamos, processamento de listas de objetos. Além disso, em AOT (como em executáveis de linha de comando ou no Flutter release mode), algumas otimizações dinâmicas se perdem – o desempenho torna-se mais previsível, porém possivelmente menor em cenários de código numérico puro comparado ao JIT quente. Isso significa que medir e ajustar a implementação especificamente para AOT pode ser importante (por exemplo, verificando se desenhar usando inteiros é mais rápido que double ou vice-versa no binário final).

Bibliotecas Dart existentes: Atualmente, para geração de imagens PNG e PDFs em Dart puro, existem bibliotecas como:

package:image: fornece utilidades para manipulação de imagens raster (PNG, JPEG) em Dart puro. Contudo, como mencionado, não é otimizado para alta performance – serve para casos simples ou tamanho moderado.

package:pdf: permite criar documentos PDF em Dart, incluindo desenho de formas vetoriais, texto e inserção de imagens. Internamente, ele não rasteriza o conteúdo (PDF é um formato vetorial), apenas monta as instruções PDF. Então, desenhar um círculo ou texto via pdf não envolve rasterização em Dart – o PDF resultante conterá vetores ou fontes que serão rasterizados pelo visualizador ao abrir o arquivo. Isso é vantajoso para qualidade (PDFs vetoriais são escaláveis).

dart:ui (no contexto Flutter) ou CanvasKit (Skia via WASM no Flutter web): mas estes fogem do escopo de “Dart puro, sem Flutter”. Em ambiente de linha de comando, não se tem dart:ui.

Assim, um desenvolvedor Dart puro que precise rasterizar vetores tem escolha limitada a implementar no próprio Dart ou fazer bindings via FFI. A interoperabilidade nativa, embora viável, adiciona complexidade (distribuir bibliotecas nativas para cada plataforma alvo, lidar com diferentes ABIs, etc.). Muitas vezes, a opção é delegar a tarefa a um serviço ou ferramenta externa. Porém, a questão proposta indica interesse justamente em soluções dentro do ecossistema Dart sem recorrer ao Flutter ou similares. Logo, é importante projetar um algoritmo que rode de forma eficiente em Dart puro, trabalhando dentro dessas limitações (e potenciais otimizações futuras do Dart).

Precisão e compatibilidade: Um ponto a considerar é que Dart usa tipagem por valor 32-bit para ints no web (compilação para JavaScript) e 64-bit nas demais plataformas. Também, operações bit a bit e deslocamentos são bem suportadas. Um rasterizador que use intensivamente aritmética de 32 bits e bit shifts (como Bresenham) vai se comportar bem tanto em VM quanto compilado para JS. Já uso pesado de 64-bit doubles pode ter implicações na performance em JS. Dado que o uso aqui é em CLI/desktop, podemos focar no Dart VM/AOT nativo (onde 64-bit floats são nativos também). Mas a portabilidade do algoritmo para web (se desejado) seria um bônus – por exemplo, uma biblioteca pura Dart que desenhe SVG ou Canvas em Flutter web – e algoritmos baseados em inteiros podem até se sair melhor nesse caso.

Em resumo, Dart impõe que sejamos conscientes sobre alocação de objetos, uso de isolates para paralelismo e o gap de desempenho frente a implementações nativas. Uma nova solução deve tentar maximizar o trabalho por operação Dart (loops apertados em listas tipadas) e minimizar interações desnecessárias com o runtime (como chamadas frequentes de métodos virtuais ou alocações). Isso garante que, mesmo sem usar C/C++ por trás, a implementação obtenha o máximo de desempenho “intrínseco” possível da VM Dart.

4. Proposta de Novo Algoritmo Otimizado para Renderização 2D em Dart

Diante das técnicas estudadas e das limitações/potencialidades do Dart, propõe-se um novo algoritmo de rasterização 2D, desenhado do zero para equilibrar desempenho e qualidade no ambiente Dart puro. Chamaremos este algoritmo de Rasterização Híbrida em Blocos para Dart (RHBD) para fins de referência.

Princípios de Funcionamento: O RHBD combina ideias de rasterização por varredura e buffer de acumulação, junto com divisão espacial (tiling):

Ele divide a imagem de saída em blocos menores (tiles), por exemplo de 32×32 pixels (o tamanho ótimo pode ser ajustado). Cada bloco é processado quase independentemente. Isso melhora a localidade de memória (cada bloco cabe facilmente em cache) e facilita paralelismo (blocos diferentes em isolates diferentes, se desejado).

Dentro de cada bloco, aplica-se uma rasterização do tipo acumulação de arestas, semelhante à usada em font-rs/stb_truetype, mas restrita ao escopo do bloco. Ou seja, para cada forma a desenhar, suas arestas que atravessam o bloco são rasterizadas em um pequeno buffer auxiliar, acumulando contribuições, e depois integradas numa passada para produzir os píxeis do bloco. Esse loop interno é linear e livre de branches pesadas, atuando num array fixo de, digamos, 32 elementos de largura (por N linhas do bloco).

Sparse global, denso local: A ideia é que áreas vazias da imagem (sem conteúdo) sejam rapidamente ignoradas ao nível de blocos – se um bloco não possui nenhuma parte de nenhuma forma, ele é simplesmente pulado. Já dentro de um bloco que contém parte de uma forma, trabalhamos de maneira densa, percorrendo todos os pixels daquele bloco com lógica uniforme. Isso pretende unir o melhor dos dois mundos: evita tocar pixel por pixel da tela inteira quando a cena é esparsa, mas quando entra no modo “desenhar”, o faz com máxima eficiência e coerência de memória.

Adaptativo ao tamanho da forma: O algoritmo pode ajustar o tamanho dos blocos ou o método de rasterização conforme o tamanho/complexidade do objeto. Por exemplo, para um texto muito pequeno (que ocupe poucos blocos), talvez compense rasterizar cada glifo com acumulação densa (mesmo fora dos blocos, direto) pois o overhead de setup de blocos supera o ganho. Já para um fundo grande retangular, pode-se detectar rapidamente que ele cobrirá muitos blocos e preenchê-los diretamente (possivelmente com uma rotina otimizada de fill).

Aritmética em ponto fixo: Para evitar custos de ponto flutuante, todas as coordenadas de entrada (vetores, curvas) seriam convertidas para um formato fixo (por exemplo, números inteiros representando 1/256 de pixel para precisão subpixel). As operações de rasterização (interseção com linhas de varredura, cálculo de alturas de aresta por pixel) podem então ser feitas usando inteiros e shifts, que o Dart lida bem. Isso evita divergência de performance entre VM JIT e AOT, e elimina erros de arredondamento inconsistente. A precisão subpixel garante que a qualidade visual (p. ex. alinhamento de curvas e fontes) não seja perdida.

Suporte a curvas Bézier: Curvas são tratadas por flattening adaptativo – subdivisão recursiva em segmentos de linha até que o erro seja menor que, digamos, 0.25 pixel (ou outro threshold). Esses segmentos lineares então são rasterizados normalmente. A subdivisão adaptativa evita gerar segmentos demais desnecessariamente: curvas quase retas serão 2 ou 3 segmentos, curvas muito curvadas terão mais refinamento. Esse pré-processamento ocorre uma vez por forma, e os segmentos resultantes podem ser reusados para múltiplos blocos. Como alternativa avançada, poder-se-ia integrar a curva diretamente no rasterizador (calculando interseções da curva com cada scanline via resolução de equações quadráticas/cúbicas), mas isso complica e possivelmente traria ponto flutuante de volta. A abordagem de flattening é mais simples e aproveita o mesmo pipeline de linhas.

Estrutura Geral do Algoritmo (Pipeline):

Preparação dos vetores: Converter todos os objetos vetoriais (segmentos de linha, curvas Bézier, contornos de fontes) em uma representação adequada:

Normalizar coordenadas ao sistema de referência do pixel (por exemplo, se há transformações ou escalas).

Subdividir curvas em segmentos de linha curtos conforme a necessidade de qualidade.

Armazenar as arestas de cada forma com coordenadas em ponto fixo (e talvez já calcular bounding boxes de cada forma para saber quais blocos ela afeta).

Organização em blocos: Dividir a área da imagem em blocos fixos (p. ex 32x32). Criar uma estrutura de índice mapeando blocos às formas/arestas que passam por ele. Por exemplo, iterar pelas formas e marcar em quais blocos do grid sua bounding box cai. Podemos ter um dicionário: chave = índice do bloco, valor = lista de arestas relevantes.

Rasterização por bloco: Para cada bloco que contém conteúdo:

Inicializar dois arrays auxiliares: A[x] e X[x] de tamanho igual à largura do bloco (por ex, 32 elementos), zerados. Esses correspondem à acumulação do algoritmo de diferenças (A para área parcial por pixel, X para diferenças cumulativas).

Para cada aresta ativa no bloco: calcular sua interseção com cada linha de varredura dentro do bloco e adicionar contribuições:

Determinar o intervalo de linhas do bloco que a aresta atravessa (com base nas coordenadas da aresta).

Para cada linha, calcular as frações de pixel cobertas (topo e base da aresta dentro daquele pixel) e adicionar a área trapezoidal correspondente em A no pixel de interseção.

Calcular a contribuição retangular infinita à direita da aresta e adicionar em X na coluna onde a aresta cruza a borda direita de um pixel (em outras palavras, marcar que a partir de tal coluna, até o fim do bloco, a área coberta aumenta de maneira constante igual à altura da aresta na linha).

Após processar todas arestas, integrar os arrays: percorrer X acumulando em uma variável s (soma prefixo) e, para cada coluna x, somar A[x] + s para obter a área coberta naquele pixel. Este valor, após normalização (clamp 0-1), dá a intensidade do pixel. Assim preenche-se os pixels do bloco. Esse loop final é muito rápido (apenas somas e atribuições linearmente nos 32 pixels, sem branches complexas).

Resultado: um bloco de pixels (p.ex. 32x32) totalmente rasterizado com os objetos que nele residem, já com antialiasing. Escrever esses pixels na posição correta do framebuffer final.

Composição: Repetir o passo 3 para todos blocos ocupados. Caso haja múltiplas formas sobrepostas, o algoritmo descrito naturalmente somará coberturas (se forem opacas, a última forma deve sobrescrever as anteriores; se houver transparências, precisaríamos adaptar o cálculo de composição – por simplicidade, assumimos formas opacas cobrindo as inferiores). Para gerenciar composição correta por camadas, podemos ordenar as formas por profundidade e rasterizar por bloco nessa ordem, ou estender a estrutura para acumular também informações de cores e alphas por pixel. Uma simplificação possível: processar formas bloco a bloco em ordem de pintura, blendando os pixels em um buffer do bloco (isso exige que percorramos as arestas em grupos por forma, mantendo uma imagem temporária do bloco).

Pós-processamento: Após todos os blocos renderizados, teremos o framebuffer completo. Daí pode-se salvar como PNG ou incorporar em PDF conforme necessário.

Opcionalmente, cache de formas: O algoritmo RHBD pode incluir um cache para formas repetitivas. Por exemplo, glyphs de fonte – renderiza-se um glifo uma vez em um bitmap pequeno (ou em múltiplos blocos) e guarda-se o resultado. Nas próximas ocorrências do mesmo caractere e tamanho, reutiliza-se o bitmap em vez de recalcular vetores. Esse cache pode ser armazenado como imagem (custa memória, mas desenho vira um simples blit) ou armazenado como lista de spans/arestas prontas para rasterização (custa recalcular pixels mas poupa parsing de curvas novamente). Em Dart, um cache de bitmaps (ex.: Map de código do char para um Uint8List do glyph) seria simples e evitaria refazer o passo geométrico todo. Isso é vital em PDF com muito texto repetido, por exemplo.

Benefícios Esperados:

Desempenho: A rasterização densa por blocos minimiza branch mispredictions e aproveita melhor as caches da CPU, enquanto a divisão espacial garante que não processaremos pixel a pixel regiões inteiras que estejam vazias. O loop interno de integração no bloco é extremamente enxuto (no limite, são poucas operações por pixel) e pode ser potencialmente autovetorizado pelo compilador JIT em algumas situações. Mesmo que não, o trabalho por iteração é pequeno e contíguo em memória, o que é ótimo para throughput.

Escalabilidade: Com blocos independentes, podemos facilmente distribuir blocos entre isolates para paralelismo. Por exemplo, 4 isolates renderizando blocos diferentes quadruplicam a velocidade em máquinas quad-core (salvo sobrecarga de coordenação). Além disso, se futuramente Dart ganhar suporte a SIMD ou parallel for, a natureza estruturada em blocos facilita aproveitar isso (poderíamos rasterizar 8 pixels de um bloco simultaneamente, etc.).

Qualidade: O algoritmo não sacrifica qualidade visual – opera com precisão subpixel e produz cobertura anti-aliased de alta fidelidade igual às técnicas consagradas (pois de fato incorpora a lógica do algoritmo do stb_truetype/font-rs, que é comprovadamente de qualidade). Curvas Bézier serão suaves devido ao refinamento adaptativo, texto terá boa nitidez (especialmente se combinado com hinting opcional na fase de preparação dos vetores).

Adequação ao Dart: A estrutura em blocos permite controlar uso de memória (cada bloco pode reusar o mesmo buffers A/X, limpando a cada nova posição). Também reduz picos de alocação – podemos alocar uma vez arrays do tamanho do bloco e reutilizar para todos os blocos, evitando pressão no GC. Aritmética inteira e loops determinados ajudam o Dart AOT a otimizar ao máximo sem depender de features ausentes. Em essência, projetamos o algoritmo para “brincar bem” com a VM Dart.

Flexibilidade de saída: Tendo rasterizado em memória, é fácil pegar os dados e tanto salvar como PNG (imagem raster) quanto embutir num PDF. Alternativamente, o algoritmo pode gerar, além do raster, algumas meta-informações que seriam úteis para PDF (por exemplo, delimitação de áreas pintadas) caso quiséssemos em vez disso produzir elementos vetoriais. Mas dado o foco em rasterização, o principal benefício é gerar bitmaps de alta qualidade rapidamente.

Em suma, o RHBD busca ser inovador ao hibridizar técnicas: aplica rasterização por diferenças (alta performance em CPU modernas) de forma localizada por blocos (evitando trabalho desnecessário), alavancando as possibilidades de paralelismo e cache-friendly design. Não é inteiramente novo matematicamente, mas a orquestração dessas estratégias focada no ambiente Dart é o diferencial – é um algoritmo pensado para ser implementado em Dart do zero, ao invés de apenas portar um existente escrito em C.

5. Sugestões de Implementação em Dart (Geração de PNG e PDF)

Implementar o algoritmo RHBD em Dart exigirá atenção a detalhes de baixo nível e integração com formatos de saída:

Estrutura de Dados: Usar os tipos fornecidos por dart:typed_data para buffers binários de pixels e cálculos. Por exemplo, o framebuffer final pode ser um Uint8List ou Uint32List (no caso de armazenar pixels RGBA de 32 bits). Os buffers auxiliares A e X dentro dos blocos podem ser Float32List (se calculando áreas em float de 0.0 a 1.0) ou mesmo Int32List (se usando unidade de área em frações de 1/coverage_scale). A escolha entre float vs int fixo deve ser testada – floats podem simplificar a integração de área, mas inteiros garantem determinismo exato. De qualquer forma, listas tipadas garantem que as operações serão realizadas nativamente e rapidamente pelo Dart VM.

Evitar Operações Desnecessárias: Dentro dos loops quentes, evitar chamar métodos ou funções Dart repetidamente. Idealmente, inlining de cálculo na própria função de rasterização. Funções pequenas podem ser marcadas como @pragma('vm:prefer-inline') para garantir inline em AOT, reduzindo overhead de chamada. Também, evitar criar objetos (como instâncias de classe) nos loops; preferir tipos primitivos locais. Por exemplo, ao percorrer arestas, em vez de ter uma classe Edge com métodos, extrair seus atributos para variáveis locais antes do loop.

Geração de PNG: Após rasterizar a imagem em um buffer, podemos usar a biblioteca package:image apenas para codificar o PNG (ela suporta criar um Image from pixels e salvar em PNG). Alternativamente, implementar um encoder PNG simples não é muito complexo (envolve compressão zlib dos dados), mas aproveitar a biblioteca existente poupa trabalho e risco. O importante é alimentar a biblioteca com os dados já prontos, sem usar as funções de desenho dela (que são lentas). Ou seja, usar Image.fromBytes(width, height, pixels, format: Format.rgba) da package:image e depois PngEncoder().encodeImage(image) para obter os bytes PNG. A performance de apenas codificar PNG não deve ser um gargalo grande (a compressão zlib custa um pouco, mas é razoável e a lib é nativa em Dart). Se for necessário otimizar, pode-se escolher um nível de compressão menor ou até usar PNG não-comprimido (grande, mas rápido).

Geração de PDF: Para compor conteúdo no PDF, há dois caminhos:

Raster no PDF: Renderizar tudo em uma imagem (como fizemos para PNG) e então colocar essa imagem inteira em uma página PDF. O package:pdf permite adicionar uma image do tipo MemoryImage (uma vez que tenha os bytes do PNG ou mesmo raw RGBA). Essa abordagem é simples, mas resulta em PDFs potencialmente pesados e não escaláveis (já que o conteúdo vira uma imagem única).

Vetorial no PDF: Aproveitar que durante a rasterização temos os vetores e enviar essas instruções ao PDF. Por exemplo, para um retângulo ou texto, em vez de rasterizar em Dart, usar as APIs do pdf para desenhar um retângulo ou escrever texto no documento. Isso manterá o PDF em formato vetorial (pequeno e de alta qualidade em zoom). Nesse caso, nosso algoritmo seria usado apenas para gerar a imagem PNG prévia ou se quisermos composições complexas (e.g., aplicar sombras, filtros) que o PDF não suporta facilmente. Se o objetivo é “compor conteúdo visual” que possivelmente inclui bitmaps gerados (como gráficos ou efeitos), podemos misturar: usar PDF vetorial para texto simples e formas básicas, e inserir imagens rasterizadas para partes onde aplicamos efeitos ou onde implementá-las em PDF seria difícil.

Em suma, para PDF, recomendamos usar o caminho vetorial sempre que possível – ou seja, reutilizar os dados de geometria antes de rasterizar. Por exemplo, se seu Dart app desenhou linhas e textos em um Canvas (simulado) para o PNG, em vez de realmente rasterizar essas linhas para PDF, simplesmente repita as operações usando as primitivas do PDF. O package:pdf tem métodos como drawLine, drawOval, drawString (associado a fontes TrueType embedadas). Isso aproveitará o melhor dos dois mundos: PNG para preview/bitmap quando necessário, e PDF vetorial para o resultado final de alta qualidade.

No caso de conteúdo que foi gerado pixel a pixel (por exemplo, se seu algoritmo produziu um fractal ou efeito procedural), aí sim insere-se a imagem raster no PDF. A biblioteca PDF suporta inserir imagens PNG ou JPEG facilmente, então basta pegar o output do PNG encoder anterior e incorporá-lo.

Integração com Texto TrueType: Para desenhar texto com nosso rasterizador, precisamos obter as curvas dos glifos. Aqui podemos usar FFI com FreeType para obter contornos? Isso quebraria a regra de Dart puro. Alternativamente, há bibliotecas puras Dart que leem fontes (por exemplo, font_kit ou similares, ou até usar .ttf via package:pdf which has font parsing). Uma ideia é aproveitar o package:pdf que já consegue embutir fontes e medir texto; possivelmente expor uma maneira de extrair o caminho vetorial de um glifo. Se não, implementar um parser simplificado de TrueType em Dart para extrair os contornos (glyf table) seria necessário. Isso é um empreendimento grande, mas talvez o escopo seja limitado se focarmos em apenas curvas quadráticas. Em todo caso, para protótipo, poder-se-ia converter fontes TTF para SVG path offline e usar essas descrições. O importante é: uma vez com o vetor do glifo, nosso algoritmo o rasteriza como qualquer outra forma. Não devemos esquecer de aplicar hinting se quisermos qualidade de fontes em tamanhos pequenos – mas hinting envolve executar bytecode da fonte, o que é complexo. Provavelmente fora do escopo implementar um engine de hinting em Dart. Podemos optar por auto-hinting simples – ex: alinhar verticalmente as alturas de ascendente/descendente do texto em pixel cheio se estiver abaixo de certo tamanho, ou mover ligeiramente nós para cair em bordas de pixel. Mesmo sem hinting, nosso anti-aliasing de alta qualidade deve gerar texto legível, apenas não tão nítido em tamanhos muito pequenos como o ClearType da Microsoft (que usa subpixel e hinting).

Testes e Ajustes Finos: Depois de implementar, é crucial medir performance em diversos cenários:

Muitas formas pequenas dispersas (para ver overhead por bloco),

Poucas formas enormes cobrindo a tela (para ver overhead de acumulação),

Texto longo vs. texto repetitivo (para avaliar ganhos de cache),

Diferentes tamanhos de bloco (16, 32, 64) para achar o melhor trade-off. Tamanho menor = mais blocos = mais overhead de iterar blocos, mas menos pixels por bloco (melhor skipping de áreas vazias); tamanho maior = processamento mais linear mas possivelmente mais pixels desnecessários se a forma só toca um canto do bloco.

Comparar execução em JIT (debug mode) e AOT (release mode) para garantir que não haja regressões inesperadas.

Considerar Limitadores: Por fim, considerar limites de memória e tempo. Em Dart, alocar um buffer do tamanho da imagem (ex: 1920x1080 RGBA = ~8MB) é trivial, mas se formos a tamanhos muito grandes (ex: A0 300DPI ~ 14000x9900 ~ 0.14 gigapixel), podemos ter problemas de memória e tempo de CPU. Talvez seja útil implementar renderização progressiva para PDF: em vez de gerar um PNG gigantesco para depois colocar no PDF, desenhar vetores gradualmente no PDF. De toda forma, para tamanhos razoáveis (até alguns milhares de pixels de dimensão), nossa abordagem deve ser viável. Caso performance ainda seja insuficiente, uma saída híbrida seria implementar partes críticas via FFI (por exemplo, escrever uma função C que rasterize um bloco com dados fornecidos) – mas isso é último caso, pois a proposta busca ser 100% Dart.

Em conclusão, a implementação do algoritmo proposto requer cuidado na escrita em Dart para não introduzir gargalos da linguagem, mas está fundamentada em técnicas sólidas de gráficos. Com ele, espera-se viabilizar em Dart puro a geração eficiente de imagens PNG e composição de PDFs com conteúdo 2D complexo, atingindo um equilíbrio entre desempenho e qualidade visual sem depender de engines externas. As sugestões acima orientam como realizar isso na prática, maximizando o uso das ferramentas disponíveis no ambiente Dart. De quebra, soluções assim poderiam até incentivar melhorias futuras no Dart (como otimizações de loop, suporte a SIMD ou bibliotecas gráficas de sistema), mas já demonstrariam que, com projeto cuidadoso, Dart pode sim realizar renderização 2D de forma competitiva dentro de seu próprio ecossistema.